{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW4 - João Lazzaro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In HW4 we were asked to implement Krusell & Smith (1998) model version with endogenous labor using the algorithm proposed by the authors. To check my results, I will try to replicate the figures and tables presented in the working paper version of the article (http://www.econ.yale.edu/smith/rcer399.pdf) since it contains more information than the final published paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Krusell & Smith Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section explains the model and I also comment on the strategies I took to solve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a competitive representative firm which uses capital $K_t$ and labor $H_t$ as inputs and faces a productivity shock $Z_t$. From the firm's problem we get the wages and capital return as a function of the aggregate states:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$w(K_t,H_t,Z_t) = (1-\\alpha)Z_tK_t^{\\alpha}H_t^{-\\alpha}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R(K_t,H_t,Z_t) = \\alpha Z_tK_t^{\\alpha-1}H_t^{1-\\alpha}+1-\\delta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Z$ is assumed to have 2 values: $[0.99,1.01]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The economy also consists of a continuum of ex ante identical households with unit mass. Each period, agents face an idiosyncratic shock $e$ that determines whether they are employed, $e_{n,t} = 1$,or unemployed, $e_{n,t} = 0$. An employed agent earns wage $w$ per unit of labor. Markets are incomplete and agents can only save through capital accumulation, individual capital is denoted by $a_t$ and $R$ is the net rate of return. The agent must also keep track of the aggregate states of the economy. We will assume that the aggregates follow the following functional forms:\n",
    "\n",
    "$ \\ln K'= b_{0,g} + b_{1,g}\\ln K$ and $ \\ln H\n",
    "'= d_{0,g} + d_{1,g}\\ln K$ when $Z=1.01$\n",
    "\n",
    "$ \\ln K'= b_{0,b} + b_{1,b}\\ln K$ and $ \\ln H\n",
    "'= d_{0,b} + d_{1,b}\\ln K$ when $Z=0.99$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent recursive problem is thus the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$V(a,e,K,H,Z) = max_{c,a',n} \\frac{\\left(c^\\eta(1-n)^{1-\\eta}\\right)^{1-\\mu}}{1-\\mu} + \\beta E\\left[V(a',e',K',H',Z')|e,K,H,Z\\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subject to the budget constraint:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$c \\leq R(K,H,Z)a -a'+w(K,H,Z)e n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a'\\geq0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the beliefs: $ \\ln K'= b_{0,g} + b_{1,g}\\ln K$ and $ \\ln H\n",
    "'= d_{0,g} + d_{1,g}\\ln K$ when $Z=1.01$\n",
    "\n",
    "$ \\ln K'= b_{0,b} + b_{1,b}\\ln K$ and $ \\ln H\n",
    "'= d_{0,b} + d_{1,b}\\ln K$ when $Z=0.99$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recursive competitive equilibrium is an allocation that solves the agent problem and the aggregates moves consistently with the beliefs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We parametrize the model following precisely Krusell & Smith parameters: \n",
    "\n",
    "$\\beta = 0.99, \\;\\delta = 0.0025,\\;\\mu = 1$ (which implies log utility). The stochastic process for $(Z,e)$ is set so the unemployment rate in good states is 0.04 and 0.1 in bad times. The average duration of good and times is 8 periods and the average duration of unemployment is 1.5 in good times and 2.5 in bad times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the Consumer Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the quantity of states, this problem is hard to solve. The usual methods I used in the previous homeworks were not able to handle this problem. Although Value Function Iteration or Euler Equation iteration worked in this case, they both were taking a ridiculous amount of time. Approximately 4 hours to solve the agent problem with a fairly small grid. The challenge was to solve the system of equations (in the case of Euler Equations) or the optimization problem (VFI) for labor and assets. It is also obvious that discrete state space that I use often for simple problems, is also not an option since it would require an enormous amount of memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of trying to speed up the solver, I decided to try another approach. Carroll's endogenous grid method proved to be very efficient in handling this problem. With a grid 6 times larger, the method solves the agent problem in less than 5 minutes since it does not involve any optimization. Usually, the endogenous grid method does not apply directly to endogenous labor problems (in the simple growth model the method would require some tweaks (see https://www.sas.upenn.edu/~jesusfv/Endogenous_Grid.pdf for a discussion) but since wages are exogenous to consumer decisions in this case it works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the labor labor consumption FOC:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac{u_n}{u_c} = w$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plugging the functional forms, we can solve for $n$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n^*(c,e,K,H,Z) = 1-\\frac{1-\\eta}{\\eta}\\frac{c}{w(K,H,Z)}$ if $e = 1$ and $n=0$ otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the intertemporal Euler equation we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$u_c(c,n) = \\beta E[ R(K',H',Z')u_c(c',n')| e,K,H,Z]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy here is to define a grid for assets in $t+1$ and to guess a functional form for $c$ so given that gues and the labor equation found above,  the right hand side of this eqution is a constant (named here RHS). Plugging the function forms for $u$ and $n^*$, we get that:\n",
    "\n",
    "$$c = \\left[ \\frac{RHS}{\\eta} \\left( \\frac{(1-\\eta)}{\\eta w(K,H,Z)}\\right)^{-(1-\\mu)(1-\\eta)}\\right]^\\frac{-1}{\\mu} $$\n",
    "if $e>0$ and $c = \\left[ \\frac{RHS}{\\eta}\\right]^\\frac{-1}{\\mu}$ otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these equations we may proceed to an usual implementation of the endogenous grid method as in Violante's slides. The code below implements the method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EE (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Interpolations, ProgressMeter\n",
    "using Distributions, Random, DataFrames, GLM\n",
    "#using Distributed, SharedArrays\n",
    "include(\"CRRA_utility.jl\")\n",
    "include(\"functions.jl\") #load some auxiliary, not interesting functions\n",
    "\n",
    "#Wages functions\n",
    "R(K::Float64,H::Float64,z::Float64;α=α::Float64,δ=δ::Float64)= z*α*K^(α-1.0)*H^(1.0-α) + (1.0-δ)\n",
    "w(K::Float64,H::Float64,z::Float64;α=α::Float64) = z*(1.0-α)*K^(α)*H^(-α)\n",
    "\n",
    "#Law of motion functions for aggregate states\n",
    "K1(K::Float64,z::Float64;b=b::Array{Float64,2},Z= Z::Array{Float64,1}) = exp(b[findfirst(Z.==z),1]+b[findfirst(Z.==z),2]*log(K))\n",
    "H0(K::Float64,z::Float64;d=d::Array{Float64,2},Z = Z::Array{Float64,1}) = exp(d[findfirst(Z.==z),1]+d[findfirst(Z.==z),2]*log(K))\n",
    "\n",
    "#Defining asset investment function:\n",
    "#c(a,e, n ,a1,k,h,z) =  R(k,h,z)*a+e*w(k,h,z)*n-a1\n",
    "a1star(c,a,e,k,h,z) = R(k,h,z)*a-c+w(k,h,z)*e*nstar(c,e,k,h,z)\n",
    "\n",
    "#defining optimal labor choice. This comes from labor FOC:\n",
    "nstar(c,e,k,h,z;η = η,lbar = lbar) = (e>0.0)*min(max((lbar - (1-η)/η * c/w(k,h,z)),0.0),lbar)\n",
    "\n",
    "\n",
    "function ENDOGENOUSGRID_KS(A::Array{Float64,1},A1::Array{Float64,1},E::Array{Float64,1},Z::Array{Float64,1},transmat::Array{Float64,2},states::NTuple,\n",
    "    K::Array{Float64,1}, H::Array{Float64,1} ,b::Array{Float64,2},d::Array{Float64,2};α=α::Float64,β = β::Float64, η=η::Float64, μ=μ::Float64,\n",
    "     tol = 1e-6, lbar=lbar::Float64 ,  policy= zeros(nA,nE,nK,nH,nZ)::Array{Float64,6},update_policy=0.5::Float64,updaterule = false)\n",
    "    #This function solves the agent problem using the endogenous grid method.\n",
    "    #A: Individual Asset grid in t!\n",
    "    #A: Individual Asset grid in t+1\n",
    "    #E: Individual productivity grid\n",
    "    #Z: Aggregate shocks grid\n",
    "    #transmat: transmat object with all the transition matrices\n",
    "    #states: A tuple which each element is a pair of possible states\n",
    "    #K: Aggregate capital grid\n",
    "    #H: Aggregate labor grid\n",
    "    #b: capital law of motion coefficients\n",
    "    #d: labor law of motion coefficients\n",
    "\n",
    "    #OPTIONAL ARGUMENTS\n",
    "    #update_policy: Damping parameter\n",
    "    #policy: Initial grid guess for the policy function\n",
    "    #udpdaterule: false for regular update rule, true for extrapolation (see below)\n",
    "    #the othere parameters are self explanatory.\n",
    "    nA::Int64 = length(A)\n",
    "    nZ::Int64 = length(Z)\n",
    "    nE::Int64 = length(E)\n",
    "    nH::Int64 = length(H)\n",
    "\n",
    "    #RETURN the grid for the agents policy functions.\n",
    "\n",
    "    #Guess for policy functions\n",
    "    #itpn = LinearInterpolation((A,E,K,H,Z),policy[:,:,:,:,:,2],\n",
    "    #extrapolation_bc=Line())\n",
    "    itpc = LinearInterpolation((A,E,K,H,Z),policy, extrapolation_bc=Line())\n",
    "    policy_c(a,e,k,h,z) = itpc(a,e,k,h,z)\n",
    "    policy_n(a,e,k,h,z) = nstar(policy_c(a,e,k,h,z),e,k,h,z)\n",
    "    policy_a(a,e,k,h,z) = a1star(policy_c(a,e,k,h,z),a,e,k,h,z)\n",
    "\n",
    "\n",
    "    #Loop st uff:\n",
    "    policy1= copy(policy) #To store updated values\n",
    "    prog = ProgressUnknown(\"Iterations:\") #timing and iteration counter, cool stuff\n",
    "    iteration ::Int64 = 0\n",
    "    distance::Float64 = 1.0\n",
    "    dist1 = policy1.-policy #\n",
    "\n",
    "    while distance > tol\n",
    "        #the function below returns the new policygrid\n",
    "    @inbounds   innerforloop!(policy1,policy_c,policy_n,b,d;\n",
    "            A=A,E=E,Z=Z,K=K,H = H,lbar = lbar,A1=A1)\n",
    "\n",
    "        #check convergence\n",
    "        distance = maximum(abs.(policy1-policy))\n",
    "\n",
    "        #error if no convergence\n",
    "        if distance == NaN || distance == Inf\n",
    "            error(\"Agent Problem did not converge\")\n",
    "        end\n",
    "\n",
    "        #see http://www.econ2.jhu.edu/People/CCarroll/SolvingMacroDSOPs.pdf (also\n",
    "        #in references directory) section 4.2 for an explanation of the parameter φ\n",
    "        #it is a clever update rule.\n",
    "        dist = copy(dist1)\n",
    "        dist1 = policy1.-policy\n",
    "        if iteration >1\n",
    "            φ = dist1./dist\n",
    "            φ[dist1.<tol] .= 0.0\n",
    "            φ[φ.>1.0] .=0.5\n",
    "            φ[0.9.<φ.<=1.0] .= 0.9\n",
    "        end\n",
    "        if iteration > 4 && updaterule\n",
    "            policy = (policy1.- φ.*policy)./(1.0.-φ)\n",
    "        else\n",
    "            policy = update_policy*policy1 + (1.0-update_policy)*policy1\n",
    "        end\n",
    "\n",
    "        #update the policy functions:\n",
    "        itpc = LinearInterpolation((A,E,K,H,Z),policy, extrapolation_bc=Line())\n",
    "        ProgressMeter.next!(prog; showvalues = [(:Distance, distance)])\n",
    "        iteration +=1\n",
    "        if iteration == 500 || iteration > 1200\n",
    "            update_policy = rand()\n",
    "        elseif iteration >10000\n",
    "            break\n",
    "        end\n",
    "\n",
    "    end\n",
    "    ProgressMeter.finish!(prog)\n",
    "    println(\"Agent problem finished with a distance of $(distance)\")\n",
    "    return  policy\n",
    "end\n",
    "\n",
    "function innerforloop!(policy1::Array{Float64,5}, policy_c::Function,policy_n,b,d;\n",
    "    A1=A1,E=E,Z=Z,K=K,H = H,lbar = lbar,A=A)\n",
    "    #Returns the updated policy grid given the policies functions\n",
    "    A0 = copy(A1)\n",
    "    for ki = 1:length(K)\n",
    "        k=K[ki]\n",
    "         for (zi,z) = enumerate(Z),(hi,h) = enumerate(H),(ei,e) = enumerate(E)\n",
    "            for (ai,a1) = enumerate(A1) #a1 is assets tommorow\n",
    "            #Find the level of assets and consumption today that generates a1 given the policy functions\n",
    "                policy1[ai,ei,ki,hi,zi],A0[ai] = EE(a1;e=e,z=z,K=k,H=h,b=b,d=d,η=η,policy_c = policy_c)\n",
    "            end\n",
    "\n",
    "            #sort the asset today (needed for the Interpolation function)\n",
    "            ordem = sortperm(A0)\n",
    "            #interpolate consumption today as a function of today's:\n",
    "            itpc0 = LinearInterpolation(A0[ordem],policy1[ordem,ei,ki,hi,zi],extrapolation_bc=Line())\n",
    "\n",
    "            #Update the grid:\n",
    "            for ai = 1:length(A)\n",
    "                if A0[1]<=A1[ai]\n",
    "                    policy1[ai,ei,ki,hi,zi] = itpc0(A1[ai])\n",
    "\n",
    "                else #If borrowing constraint bids:\n",
    "                    policy1[ai,ei,ki,hi,zi] = η*(R(k,h,z)*A0[ai]- A1[1] + w(k,h,z)*e*lbar) \n",
    "                    #This formula comes from finding the solution of the fixed point c:\n",
    "                    # c = R(k,h,z)*A0[ai]- A1[1] + w(k,h,z)*e*nstar(c,e,k,h,z)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return policy1\n",
    "end\n",
    "\n",
    "function EE(a1;e=E[e]::Float64,\n",
    "    z=Z[z]::Float64,K=K[k]::Float64,H=H[h]::Float64,states=states::NTuple{4,Array{Float64,1}},\n",
    "    b=b::Array{Float64,2},d=d::Array{Float64,2},η=η::Float64,Z = Z,E = E,policy_c=policy_c)\n",
    "    #a1 is the asset level tommorow\n",
    "    #Finds assets today as a function of assets tomorrow using the Euler equations\n",
    "    i::Int64 = findfirstn(states,[z,e]) #find the current state index\n",
    "    k1::Float64 = K1(K,states[i][1];b=b) #Aggregate states tommorow given today\n",
    "    h1::Float64 = H0(k1,states[i][1];d=d)\n",
    "    RHS1::Float64 = 0.0 #Find the RHS of the consumption FOC uct'= βE[R uct1 ']\n",
    "    for e1=1:nE, z1 = 1:nZ #for all possible states tommorow\n",
    "        j::Int64 = findfirstn(states,[Z[z1],E[e1]]) #find the tommorow state index\n",
    "        c1::Float64 = policy_c(a1,E[e1],k1,h1,Z[z1]) #find consumption in t+1 given policy function\n",
    "        a2::Float64 = a1star(c1,a1,E[e1],k1,h1,Z[z1]) #find assets in t+2 given policy function\n",
    "        n1::Float64 = nstar(c1,E[e1],k1,h1,Z[z1]) #find labor in t+1 given policy function\n",
    "        l1::Float64 = lbar - n1 #leisure\n",
    "        RHS1 += β * transmat[i,j]*R(k1,h1,Z[z1])*uc(c1,l1) #The RHS for the state j given i\n",
    "    end\n",
    "\n",
    "    #Find the level of consumption today that generates a1 given the policy functions\n",
    "    if e > 0.0\n",
    "        c = (RHS1/η * ((1-η)/(η*e*w(K,H,z)))^(-(1-μ)*(1-η)))^(-1/μ)\n",
    "    else\n",
    "        c = (RHS1/η *lbar^(-(1-μ)*(1-η)))^(1/(η*(1-μ)-1))\n",
    "    end\n",
    "    #Find the consitent asset level for today (endogenous grid)\n",
    "    a = c+a1-e*w(K,H,z)*nstar(c,e,K,H,z)\n",
    "\n",
    "    return c,a\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Aggregate States law of motion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm proposed by Krusell & Smith is fairly simple. It is enough to simulate the economy for a large number of agents and periods and then regress the law of motion coeffients by OLS. One quick comment on the generation of shocks is that I must make sure that the distribution is consistent. For example, I generate the series of $Z$ and for each agent the draw $e_{n,t}$ must take into acount $e_{n,t-1},Z_{t-1},Z_t$ since the shocks are not independent.\n",
    "\n",
    "During the simulation I took some time to figure out that one must ensure that labor market clear every period (since capital is predetermined, this is not an issue in that market). To do so, we must each period guess an initial aggregate state for labor and then loop until the convergence (i.e. the aggregate of the indiviual labor decisions equals the aggregate labor guess). The code below implements the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KrusselSmithENDOGENOUS (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function KrusselSmithENDOGENOUS(A::Array{Float64,1},A1::Array{Float64,1},\n",
    "    E::Array{Float64,1},Z::Array{Float64,1},tmat::TransitionMatrix,states::NTuple{4,Array{Float64,1}},\n",
    "    K::Array{Float64,1},H::Array{Float64,1},  b::Array{Float64,2},d::Array{Float64,2};\n",
    "    α = α::Float64,β = β::Float64, η = η::Float64, μ=μ::Float64, tol= 1e-6::Float64,\n",
    "    update_policy=0.5::Float64,updateb= 0.3::Float64,N::Int64=5000,T::Int64=11000,\n",
    "    discard::Int64=1000,seed::Int64= 2803,lbar=lbar::Float64,updaterule = false)\n",
    "    #This performs KS algorithm\n",
    "    #A: Individual Asset grid in t!\n",
    "    #A1: Individual Asset grid in t+1\n",
    "    #E: Individual productivity grid\n",
    "    #Z: Aggregate shocks grid\n",
    "    #tmat: transmat object with all the transition matrices\n",
    "    #states: A tuple which each element is a pair of possible states\n",
    "    #K: Aggregate capital grid\n",
    "    #H: Aggregate labor grid\n",
    "    #b: capital law of motion coefficients\n",
    "    #d: labor law of motion coefficients\n",
    "\n",
    "    #OPTIONAL ARGUMENTS\n",
    "    #update_policy: Damping parameter for the agent Problem\n",
    "    #update_b: Damping parameter for the law of motion updates\n",
    "    #N: Number of agents in the simulation\n",
    "    #T: Length of the simulated time series\n",
    "    #discard: number of time periods discarded for ergodicity\n",
    "    #seed: set the random seed for comparable results\n",
    "    #policy: Initial grid guess for the policy function\n",
    "    #the othere parameters are self explanatory.\n",
    "\n",
    "\n",
    "    #RETURN\n",
    "    #b: Updated parameter for aggregate capital law of motions\n",
    "    #d: Updated parameter for aggregate labor law of motions\n",
    "    #nsim: NxT matrix with simulated labor path for each agent n\n",
    "    #asim: NxT matrix with simulated assets path for each agent n\n",
    "    #Ksim: T vector with simulated aggregate  capital\n",
    "    #Hsim: T vector with simulated aggregate  Labor ,\n",
    "    #policygrid: Grid with agents policy functions\n",
    "    #K: new updated grid for aggregate capita (not used for now),\n",
    "    #R2b,R2d: R-squared of b and d regressions\n",
    "    #zsimd: T vector with simulated aggregate shocks\n",
    "    #esim: NxT matrix with idyosincratic employment shock for each agent\n",
    "\n",
    "    #Getting lengths\n",
    "    nA::Int64 = length(A)\n",
    "    nZ::Int64 = length(Z)\n",
    "    nE::Int64 = length(E)\n",
    "    nH::Int64 = length(H)\n",
    "    nK::Int64 = length(K)\n",
    "\n",
    "    println(\"Starting Krusell Smith. We are using $(nA) gridpoints for assets and\")\n",
    "    println(\"a sample of N=$(N), T=$(T). Go somewhere else, this will take a while.\")\n",
    "\n",
    "    transmat::Array{Float64,2} = tmat.P #Getting the transition matrix for the agent\n",
    "\n",
    "    d=d::Array{Float64,2}\n",
    "   \n",
    "    #getting the shocks\n",
    "   \n",
    "    zi_shock,epsi_shock = generate_shocks(KSParameter(); z_shock_size = T, population = N)\n",
    "\n",
    "    zsim = fill(1.01,T)\n",
    "    zsim[zi_shock.==2].=0.99\n",
    "    zsimd::Array{Float64,1} = zsim[discard+1:end] #Discarded simulated values for z\n",
    "\n",
    "\n",
    "    esim = fill(1.0,N,T)\n",
    "    esim[epsi_shock' .== 2] .= 0.0\n",
    "\n",
    "    meanUgood = 1-mean(esim[:,zsim.==Z[2]])\n",
    "    meanUbad = 1-mean(esim[:,zsim.==Z[1]])\n",
    "\n",
    "    println(\"Unemployment in bad state is $(meanUbad) and $(meanUgood) in good states.\")\n",
    "\n",
    "    #predefining variables\n",
    "    asim::Array{Float64,2} = rand(K[1]:0.1:K[end],N,T) #the initial assets will generate aggregate assets in the grid\n",
    "    Ksim::Array{Float64,1} = ones(T)\n",
    "    Hsim::Array{Float64,1} = ones(T)\n",
    "    nsim::Array{Float64,2} = ones(N,T)\n",
    "    R2d::Array{Float64,1} = ones(2)\n",
    "    R2b::Array{Float64,1} = ones(2)\n",
    "\n",
    "    #First guessess for Policy\n",
    "    policygrid::Array{Float64,5} =  ones(nA,nE,nK,nH,nZ)\n",
    "    for (zi,z) = enumerate(Z),(hi,h) = enumerate(H),(ki,k) = enumerate(K),(ei,e)=enumerate(E),(ai,a1)=enumerate(A)\n",
    "        policygrid[ai,ei,ki,hi,zi] = 0.9*a1\n",
    "    end\n",
    "    itpc = LinearInterpolation((A,E,K,H,Z),policygrid, extrapolation_bc=Line())\n",
    "    multiple100::Int64 = 0\n",
    "\n",
    "    policy_c(a,e,k,h,z) = itpc(a,e,k,h,z)\n",
    "    policy_n(a,e,k,h,z) = nstar(policy_c(a,e,k,h,z),e,k,h,z)\n",
    "    policy_a(a,e,k,h,z) = a1star(policy_c(a,e,k,h,z),a,e,k,h,z)\n",
    "\n",
    "    #loop stuff\n",
    "    dist::Float64 = 1.0\n",
    "    iteration::Int64 = 0\n",
    "    b1::Array{Float64,2} = copy(b)\n",
    "    d1::Array{Float64,2} = copy(d) #to store updated values for b and d\n",
    "\n",
    "    Ht::Float64 = 1.0\n",
    "\n",
    "    while (dist>tol)\n",
    "\n",
    "        println(\"Solving the agent problem\")\n",
    "        #Solve the agent problem:\n",
    "        policygrid = ENDOGENOUSGRID_KS(A,A1,E,Z,transmat,states,K, H,b,d;policy= policygrid,update_policy=update_policy,tol = tol,updaterule = updaterule)\n",
    "        itpc = LinearInterpolation((A,E,K,H,Z),policygrid, extrapolation_bc=Line())\n",
    "        println(\"Agent Problem solved!\")\n",
    "\n",
    "\n",
    "        loading = Progress(T, 1,\"Simulating the economy.\", 30)   #For loop loading bar minimum update interval: 1 second\n",
    "        #Simulating the economy\n",
    "        for t=1:T\n",
    "            Ksim[t] = mean(asim[:,t]) #Aggregate capital is the mean of the capital decided yesterday\n",
    "            #First guess for aggregate labor:\n",
    "            Ht = H0(Ksim[t],zsim[t];d=d)\n",
    "            #Find aggregate labor that clears the market:\n",
    "            internaldist = 10.0\n",
    "            its = 0\n",
    "                while internaldist>1e-6 && its < 500\n",
    "                    Threads.@threads for n=1:N\n",
    "                        nsim[n,t] = policy_n(asim[n,t],esim[n,t],Ksim[t],Ht,zsim[t]) #Store each agent labor decision\n",
    "                    end\n",
    "                    Hsim[t] = mean(nsim[:,t])\n",
    "                    internaldist = abs(Hsim[t] - Ht)\n",
    "                    Ht = Hsim[t]\n",
    "                    its+=1\n",
    "                end\n",
    "\n",
    "                if t<T\n",
    "                    asim[:,t+1] .= policy_a.(asim[:,t],esim[:,t],Ksim[t],Ht,zsim[t]) #Store each agent asset decision\n",
    "                end\n",
    "            next!(loading) #loading bar stuff\n",
    "        end\n",
    "\n",
    "\n",
    "        println(\"Economy simulated, let's run the regression\")\n",
    "        #Running the regressions\n",
    "        for i=1:nZ #for each state\n",
    "            datad = DataFrame(Xd = log.(Ksim[discard+1:end][zsimd.==Z[i]]),\n",
    "            Yd = log.(Hsim[discard+1:end][zsimd.==Z[i]])) #take log of capital and labor and dataframe it, note that I discard observations\n",
    "            olsd = lm(@formula(Yd ~ Xd), datad) #regress\n",
    "            d1[i,:] = coef(olsd) #get coefficients\n",
    "            R2d[i] = r2(olsd) #and R2\n",
    "\n",
    "            datab = DataFrame(Xb = log.(Ksim[discard+1:end-1][zsimd[1:end-1].==Z[i]]),\n",
    "            Yb = log.(Ksim[discard+2:end][zsimd[1:end-1].==Z[i]]))#take log of capital and capital tomorrow and dataframe it, note that I discard observations\n",
    "            olsb = lm(@formula(Yb ~ Xb), datab) #regress\n",
    "            b1[i,:] = coef(olsb)#get coefficients\n",
    "            R2b[i] = r2(olsb) #and R2\n",
    "\n",
    "        end\n",
    "\n",
    "        #kmin::Float64 =  max(mean(Ksim)-20.0,eps())\n",
    "        #kmax::Float64 =  mean(Ksim)+20.0\n",
    "        #K::Array{Float64,1} = range(kmin,stop = kmax, length = nK).^1\n",
    "\n",
    "        #check convergence\n",
    "        dist = maximum(vcat(abs.(b.-b1),abs.(d.-d1)))\n",
    "\n",
    "        #update law of motions with a damping parameter\n",
    "        b = updateb.*b1 .+ (1-updateb).*b\n",
    "        d = updateb.*d1 .+ (1-updateb).*d\n",
    "\n",
    "        iteration += 1\n",
    "        println(\"In iteration $(iteration), law distance is $(dist)\")\n",
    "        println(\"b = $(b) and\")\n",
    "        println(\"d = $(d)\")\n",
    "        println(\"Aggregate labor mean is $(mean(Hsim))\")\n",
    "        println(\"Aggregate Capital mean is $(mean(Ksim))\")\n",
    "        println(\"Aggregate Capital R2 is $(R2b)\")\n",
    "        println(\"Aggregate Labor R2 is $(R2d)\")\n",
    "    end\n",
    "    #=Drop first discard observations:\n",
    "    Hsim = Hsim[discard+1:end]\n",
    "    Ksim = Ksim[discard+1:end]\n",
    "    nsim = nsim[:,discard+1:end]\n",
    "    asim = asim[:,discard+1:end]\n",
    "    esim = asim[:,discard+1:end]=#\n",
    "    println(\"Krussell Smith done!\")\n",
    "    return b, d,  nsim, asim, Ksim, Hsim,policygrid,K,R2b,R2d,zsimd,esim\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't run the code on this notebook because it does not look nice and also the server runs it much faster than my computer. I load the directly the results of a previous run of the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "SystemError: opening file \"Z:\\\\ECON_8185\\\\Anmol\\\\HW4\\\\save_variables\": Permission denied",
     "output_type": "error",
     "traceback": [
      "SystemError: opening file \"Z:\\\\ECON_8185\\\\Anmol\\\\HW4\\\\save_variables\": Permission denied",
      "",
      "Stacktrace:",
      " [1] #systemerror#43(::Nothing, ::Function, ::String, ::Bool) at .\\error.jl:134",
      " [2] systemerror at .\\error.jl:134 [inlined]",
      " [3] #open#309(::Bool, ::Bool, ::Bool, ::Bool, ::Bool, ::Function, ::String) at .\\iostream.jl:289",
      " [4] #open at C:\\Users\\jgsla\\.juliapro\\JuliaPro_v1.1.1.1\\packages\\JLD2\\KjBIK\\src\\mmapio.jl:0 [inlined]",
      " [5] Type at C:\\Users\\jgsla\\.juliapro\\JuliaPro_v1.1.1.1\\packages\\JLD2\\KjBIK\\src\\mmapio.jl:100 [inlined]",
      " [6] openfile at C:\\Users\\jgsla\\.juliapro\\JuliaPro_v1.1.1.1\\packages\\JLD2\\KjBIK\\src\\JLD2.jl:194 [inlined]",
      " [7] #jldopen#9(::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Type{JLD2.MmapIO}) at C:\\Users\\jgsla\\.juliapro\\JuliaPro_v1.1.1.1\\packages\\JLD2\\KjBIK\\src\\JLD2.jl:231",
      " [8] jldopen at C:\\Users\\jgsla\\.juliapro\\JuliaPro_v1.1.1.1\\packages\\JLD2\\KjBIK\\src\\JLD2.jl:203 [inlined] (repeats 2 times)",
      " [9] #jldopen#10(::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::Function, ::String, ::String) at C:\\Users\\jgsla\\.juliapro\\JuliaPro_v1.1.1.1\\packages\\JLD2\\KjBIK\\src\\JLD2.jl:293",
      " [10] jldopen at C:\\Users\\jgsla\\.juliapro\\JuliaPro_v1.1.1.1\\packages\\JLD2\\KjBIK\\src\\JLD2.jl:288 [inlined] (repeats 2 times)",
      " [11] @load(::LineNumberNode, ::Module, ::Any, ::Vararg{Any,N} where N) at C:\\Users\\jgsla\\.juliapro\\JuliaPro_v1.1.1.1\\packages\\JLD2\\KjBIK\\src\\loadsave.jl:64"
     ]
    }
   ],
   "source": [
    "using JLD2, FileIO\n",
    "@load \"Z:\\\\ECON_8185\\\\Anmol\\\\HW4\\\\save_variables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
